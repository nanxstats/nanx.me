---
title: Implementing Triplet Losses for Implicit Feedback Recommender Systems with R and Keras
author: Nan Xiao
date: "2018-08-29T19:30:00"
slug: triplet-loss-r-keras
categories:
  - machine learning
tags:
  - deep learning
  - triplet loss
  - metric learning
  - recommender system
  - collaborative filtering
  - implicit feedback
  - Keras
  - R
meta_img: image/three-palms-jamie-davies.jpg
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<p>All the R code for this post is available on GitHub: <a href="https://github.com/nanxstats/deep-learning-recipes">nanxstats/deep-learning-recipes</a>.</p>
<div class="figure">
<img src="/image/three-palms-jamie-davies.jpg" alt="" />
<p class="caption">Photo: <a href="https://unsplash.com/photos/eZt5mvF7RcU">Three Palms</a> by Jamie Davies</p>
</div>
<p>At the end of our <a href="https://nanx.me/blog/post/recsys-binary-implicit-feedback-r-keras/">last post</a>, I briefly mentioned that the triplet loss function is a more proper loss designed for both recommendation problems with implicit feedback data and distance metric learning problems. For its importance in solving these practical problems, and also as an excellent programming exercise, I decided to implement it with R and Keras.</p>
<div id="triplet-loss" class="section level2">
<h2>Triplet Loss</h2>
<p>The triplet loss makes us focus on the core of many supervised/unsupervised learning problems: learning better representations for data. The idea is pretty simple: we want to learn a custom distance metric or (low-rank) representation for our data, such that under this new metric or representation, the distance between “similar” observations is smaller, and the distance between “dissimilar” observations is larger. Here the definition of “similar” or “dissimilar” observations may come from some side information.</p>
<p>The idea of learning a global Mahalanobis distance metric was first formalized by <a href="https://dl.acm.org/citation.cfm?id=2968618.2968683">Xing et al.</a> as a convex optimization problem. The <a href="http://jmlr.csail.mit.edu/papers/volume10/weinberger09a/weinberger09a.pdf">LMNN by Weinberger and Saul</a> is the work that first formulated the metric learning problem as a localized large margin learning problem with “triplets”, partially inspired by the SVM objective function. The triplet loss was further popularized by the <a href="https://arxiv.org/abs/1503.03832">FaceNet by Schroff et al.</a> in the computer vision and especially the face recognition community. A margin-based triplet loss function looks like this:</p>
<p><span class="math display">\[L_\text{margin}(a, p, n) = \sum \max(0, f(a, p) - f(a, n) + \varepsilon)\]</span></p>
<p>where <span class="math inline">\(a\)</span> is an “anchor” observation. <span class="math inline">\(p\)</span> is the “positive” sample which should be closer to <span class="math inline">\(a\)</span> than the “negative” sample <span class="math inline">\(n\)</span>. We will need many such triplets <span class="math inline">\(\{a, p, n\}\)</span>. <span class="math inline">\(f\)</span> is the transformation we want to learn. <span class="math inline">\(\varepsilon\)</span> is a constant number larger than zero (tuning parameter). A natural interpretation of the loss function: the learned metric should separate the negative sample <span class="math inline">\(n\)</span> from the positive sample <span class="math inline">\(n\)</span> at least by a positive margin <span class="math inline">\(\varepsilon\)</span>.</p>
</div>
<div id="data-and-model" class="section level2">
<h2>Data and Model</h2>
<p>To make things easier to understand, this time we will use the MovieLens data as the example. Naturally, we will also use the jargon of users/items to denote the two parties presented in a recommender system.</p>
<p>We binarized the 1 to 5 ratings to make it binary (interacting or non-interacting user-item pairs) implicit feedback data. To construct the triplets, we sample from the interacting user-items pairs and combine them with randomly sampled non-interaction items for the users.</p>
<p>The model looks like this:</p>
<div class="figure">
<img src="triplet-loss-model-keras.png" alt="" />
<p class="caption">Figure: A barebone matrix factorization model with a triplet loss for recommender systems with implicit feedback data.</p>
</div>
<p>From the figure, the low-rank, dense embeddings for users and items are the inputs for the loss function (the Lambda layer). By minimizing the loss function, we achieved our goal: learning representations for users and items. Note that the embedding layer for items is shared by the positive and negative items since they are inherently both items thus should use the same representation.</p>
</div>
<div id="implementation" class="section level2">
<h2>Implementation</h2>
<p>Unlike our <a href="https://nanx.me/blog/post/recsys-binary-implicit-feedback-r-keras/">last post</a> which modeled this as a classification problem, we don’t have the “labels” in the traditional sense here. Instead, the training loss itself will be the output as is shown above. Therefore, it is a little tricky to implement this with Keras because we need to build a custom loss function, build a custom metric function, and finally, build a custom prediction function. This is precisely why it would be a good programming exercise.</p>
<p>The closest <a href="https://github.com/maciejkula/triplet_recommendations_keras">reference implementation</a> I could find is written in Python. Unfortunately, the code is a bit outdated and doesn’t play well with the latest Keras API. So I reimplemented the model in R and made it running on the latest Keras and Tensorflow backend successfully, with the help of the functional style <a href="https://keras.io/layers/core/#lambda">lambda layers</a>.</p>
</div>
<div id="performance-evaluation" class="section level2">
<h2>Performance Evaluation</h2>
<p>The custom performance metric we implemented is a user-averaged AUC. In essence, for each user in the test set, we predict the probability if an item will be preferred by the user on all items in the test set. We then compute the AUC based on these predictions for this user, do this for all users, and average all the AUC values. Intuitively, this metric can roughly reflect the probability that a randomly selected positive item will be ranked higher than a randomly selected negative item for users.</p>
<p>The loss and AUC change on the training/test set is visualized below.</p>
<div class="figure">
<img src="triplet-loss-margin-movielens.png" alt="" />
<p class="caption">Figure: The first 20 epochs: loss and user-averaged AUC for the margin-based triplet loss model.</p>
</div>
</div>
<div id="the-bpr-triplet-loss" class="section level2">
<h2>The BPR Triplet Loss</h2>
<p>What our reference implementation had is another type of triplet loss, namely, the <a href="https://arxiv.org/abs/1205.2618">Bayesian Personalized Ranking (BPR) loss</a>:</p>
<p><span class="math display">\[L_\text{BPR}(a, p, n) = \sum \big(1 - \sigma(f(a, p) - f(a, n)) \big)\]</span></p>
<p>where <span class="math inline">\(\sigma\)</span> is the sigmoid function. For the sake of completeness, I also implemented it. It has a strikingly similar performance to the margin-based model for our data here, while it converges faster with the benefit of not needing to tune the margin parameter of the loss.</p>
<div class="figure">
<img src="triplet-loss-bpr-movielens.png" alt="" />
<p class="caption">Figure: The first 20 epochs: loss and user-averaged AUC for the BPR triplet loss model.</p>
</div>
</div>
<div id="comments" class="section level2">
<h2>Comments</h2>
<p><strong>Hard negative mining.</strong> A crucial aspect for improving the performance of models with a triplet loss is about selecting or constructing more hard-to-learn triplets which can help you learn the representations or metrics better. This is often called the “hard negative mining” problem. The <a href="https://arxiv.org/abs/1503.03832">FaceNet paper</a> described their triplet selection approach. Here is also a <a href="https://omoindrot.github.io/triplet-loss">good post</a> explaining more details on this.</p>
<p><strong>Applications.</strong> The bar of applying this method is relatively low because sometimes the required data is more accessible than fully labeled data. Conceptually, this idea can be applied to any learning problems where we can construct the triplets. An extreme case is the recsys with implicit feedback data we just showed: we only know the relative preference between entities (e.g., user’s relative preference for items). The more common scenarios are where the true labels of data are difficult to get, but one might know the distance/similarity relationships between entities (images, text, human genomes).</p>
</div>
