---
title: "tinytopics: GPU-accelerated topic modeling via constrained neural Poisson NMF"
author: "Nan Xiao"
date: "2024-10-26T20:42:00"
slug: tinytopics
categories: []
tags:
  - Python
  - Python packages
  - PyTorch
  - topic modeling
  - matrix factorization
  - natural language processing
  - GPU
  - deep learning
  - neural network
bibliography: "tinytopics.bib"
meta_img: "image/tim-foster-jhovC0t8f-8-unsplash.jpg"
description: >
  Introducing tinytopics, a lightweight Python package for GPU-accelerated
  topic modeling using constrained neural Poisson NMF.
  Built on PyTorch, tinytopics offers scalable topic modeling for large datasets.
  This post shares the motivation, features, and examples to help you get
  started with tinytopics.
---



<div class="float">
<img src="/image/tim-foster-jhovC0t8f-8-unsplash.jpg" alt="Downhill mountain biking. Photo by Tim Foster." />
<div class="figcaption">Downhill mountain biking.
Photo by <a href="https://unsplash.com/photos/jhovC0t8f-8">Tim Foster</a>.</div>
</div>
<style type="text/css">
.content .blog-post-title { font-size: 2.1875rem; }
</style>
<p>I’m excited to share that my first Python package,
<a href="https://nanx.me/tinytopics/">tinytopics</a>,
is now available on PyPI. You can install it using</p>
<pre class="bash"><code>pip3 install tinytopics</code></pre>
<p>tinytopics is a minimalist solution designed to scale up topic modeling
tasks on CPUs and GPUs using PyTorch.</p>
<div id="motivation" class="section level2">
<h2>Motivation</h2>
<p>Fitting topic models at scale using classical algorithms on CPUs can be slow.
<span class="citation">Carbonetto et al. (<a href="#ref-carbonetto2022nmf">2022</a>)</span> demonstrated the equivalence between Poisson non-negative matrix factorization (NMF) and multinomial topic model likelihoods.
They proposed a novel optimization strategy: fit a Poisson NMF via
coordinate descent, then recover the corresponding topic model through
a simple transformation. This method was implemented in their R package,
<a href="https://cran.r-project.org/package=fastTopics">fastTopics</a>.</p>
<p>Building on this theoretical insight, tinytopics takes a different
approach by directly optimizing a sum-to-one constrained neural Poisson NMF
problem with stochastic gradient methods.</p>
</div>
<div id="when-to-use-tinytopics" class="section level2">
<h2>When to use tinytopics</h2>
<p>For standard topic modeling tasks, I think fastTopics is already an excellent
solution because it is fast and can generate high-quality models with default
settings (<a href="https://nanx.me/blog/post/sensible-defaults/">sensible defaults</a>).
Plus, I can’t praise its ergonomic API design enough, which can be
summarized as “topic modeling for humans”.</p>
<p>You might find tinytopics a viable alternative option if you care more about:</p>
<ul>
<li><strong>Scale and speed</strong>. For extra-large datasets, tinytopics can leverage GPUs to
accelerate computations. You can also use <a href="https://pytorch.org/tutorials/distributed/home.html">PyTorch distributed
training</a> to scale
across multiple GPUs or machines if single card VRAM is insufficient.</li>
<li><strong>Model customization</strong>. The constrained neural Poisson NMF in tinytopics
is a flexible, differentiable model. You can adapt it by adding new layers,
incorporating regularization, or even integrating other data modalities,
such as images or videos, for joint modeling.</li>
</ul>
</div>
<div id="when-not-to-use-tinytopics" class="section level2">
<h2>When not to use tinytopics</h2>
<p>tinytopics might not be the best option if you need:</p>
<ul>
<li><strong>Theoretical guarantees</strong>. Since tinytopics solves an approximate version
of the exact Poisson NMF problem using stochastic gradient methods, it may
lack the convergence, consistency, and identifiability guarantees often
found in classical algorithms.</li>
<li><strong>Minimal parameter tuning</strong>. While tinytopics uses modern stochastic gradient
optimizers and schedulers, you might still need to adjust hyperparameters to
get optimal results, depending on your dataset. This can require some
empirical fine-tuning and can be tricky to get right.</li>
</ul>
</div>
<div id="examples" class="section level2">
<h2>Examples</h2>
<p>I created three vignettes to demonstrate tinytopics’ functionality,
result accuracy, and performance on GPU:</p>
<ul>
<li><a href="https://nanx.me/tinytopics/articles/get-started/">Getting started guide with synthetic count data</a>.</li>
<li><a href="https://nanx.me/tinytopics/articles/benchmark/">CPU vs. GPU training speed benchmark</a>.</li>
<li><a href="https://nanx.me/tinytopics/articles/text/">Text data topic modeling example</a>.</li>
</ul>
</div>
<div id="python-toolchain-that-simplified-development" class="section level2">
<h2>Python toolchain that simplified development</h2>
<p>I wanted to thank the creators of the following software for improving the
Python package development experience:</p>
<ul>
<li><a href="https://pytorch.org/">PyTorch</a>.
It just works. If you are going to build for GPU, choose PyTorch.</li>
<li><a href="https://squidfunk.github.io/mkdocs-material/">mkdocs-material</a>.
A Markdown-first documentation website framework that, with mkdocs and mkdocstrings,
makes package documentation generation efficient and enjoyable.</li>
<li><a href="https://rye.astral.sh/">Rye</a>.
The package and project environment manager I wish I had known earlier!
I’m grateful that my friend <a href="https://github.com/svm-zhang">Simo</a> suggested
Rye and Neovim so that I can focus on writing code and be more productive.</li>
</ul>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<style type="text/css">
.references { font-size: 1.125rem; }
</style>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-carbonetto2022nmf" class="csl-entry">
Carbonetto, Peter, Abhishek Sarkar, Zihao Wang, and Matthew Stephens. 2022. <span>“Non-Negative Matrix Factorization Algorithms Greatly Improve Topic Model Fits.”</span> <em>arXiv Preprint arXiv:2105.13440</em>. <a href="https://arxiv.org/abs/2105.13440">https://arxiv.org/abs/2105.13440</a>.
</div>
</div>
</div>
